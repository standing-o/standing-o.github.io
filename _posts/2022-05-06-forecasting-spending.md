---
title: "[Dacon] ì†Œë¹„ì ë°ì´í„° ê¸°ë°˜ ì†Œë¹„ ì˜ˆì¸¡ ê²½ì§„ëŒ€íšŒ"
date: 2022-05-06 16:00:00 +/-TTTT
categories: [Competition, Dacon]
tags: [ë°ì´ì½˜, dacon, ì†Œë¹„ì˜ˆì¸¡, regression, lightgbm, xgboost, elasticnet, ensemble]
---

--------------------------------


- ë³¸ í¬ìŠ¤íŒ…ì€ ê°„ë‹¨í•œ ë°ì´í„° ì „ì²˜ë¦¬ ë° EDAì™€ Ensemble(Elasticnet, LightGBM, XGBoost) ë“±ì˜ ë‚´ìš©ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.  
- ì½”ë“œì‹¤í–‰ì€ Google Colabì˜ CPU, Standard RAM í™˜ê²½ì—ì„œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  
â” [ë°ì´ì½˜ì—ì„œ ì½ê¸°](https://dacon.io/codeshare/4881)  

  

## **0. Import Packages**

```python
from google.colab import drive
drive.mount('/content/drive')
```

<pre>
Mounted at /content/drive
</pre>

```python
!pip install folium==0.2.1
!pip install markupsafe==2.0.1
!pip install -U pandas-profiling
```


```python
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import sklearn
import pandas_profiling
import seaborn as sns
import random as rn
import os
import scipy.stats as stats
import datetime
import calendar

from sklearn.preprocessing import PowerTransformer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

from sklearn.model_selection import GridSearchCV, cross_val_score, RepeatedKFold
from sklearn import metrics

from sklearn.linear_model import ElasticNet
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor

from collections import Counter
import warnings

%matplotlib inline
warnings.filterwarnings(action='ignore')
```


```python
print("numpy version: {}". format(np.__version__))
print("pandas version: {}". format(pd.__version__))
print("matplotlib version: {}". format(matplotlib.__version__))
print("scikit-learn version: {}". format(sklearn.__version__))
print("xgboost version: {}". format(xgb.__version__))
print("lightgbm version: {}". format(lgb.__version__))
```

<pre>
numpy version: 1.21.6
pandas version: 1.3.5
matplotlib version: 3.2.2
scikit-learn version: 1.0.2
xgboost version: 0.90
lightgbm version: 2.2.3
</pre>

```python
# reproducibility
seed_num = 42   ####
np.random.seed(seed_num)
rn.seed(seed_num)
os.environ['PYTHONHASHSEED']=str(seed_num)
```

## **1. Load and Check Dataset**


```python
train = pd.read_csv('/content/drive/MyDrive/Consumer_spending_forecast/dataset/train.csv')
test = pd.read_csv('/content/drive/MyDrive/Consumer_spending_forecast/dataset/test.csv')

print(train.shape)
train.head()
```

<pre>
(1108, 22)
</pre>
<pre>
   id  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \
0   0        1974      Master       Together  46014.0        1         1   
1   1        1962  Graduation         Single  76624.0        0         1   
2   2        1951  Graduation        Married  75903.0        0         1   
3   3        1974       Basic        Married  18393.0        1         0   
4   4        1946         PhD       Together  64014.0        2         1   

  Dt_Customer  Recency  NumDealsPurchases  ...  NumStorePurchases  \
0  21-01-2013       21                 10  ...                  8   
1  24-05-2014       68                  1  ...                  7   
2  08-04-2013       50                  2  ...                  9   
3  29-03-2014        2                  2  ...                  3   
4  10-06-2014       56                  7  ...                  5   

   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \
0                  7             0             0             0             0   
1                  1             1             0             0             0   
2                  3             0             0             0             0   
3                  8             0             0             0             0   
4                  7             0             0             0             1   

   AcceptedCmp2  Complain  Response  target  
0             0         0         0     541  
1             0         0         0     899  
2             0         0         0     901  
3             0         0         0      50  
4             0         0         0     444  

[5 rows x 22 columns]
</pre>

```python
pr = train.profile_report()
pr.to_file('/content/drive/MyDrive/Consumer_spending_forecast/pr_report.html')
pr
```
![pandas_profiling](/assets/img/for_post/20220506-1.png)

### **Summary of Pandas profiling : Alert**

#### **High Correlation**

- `Income`-`Kidhome`-`NumWebPurchases`-`NumStorePurchases`-`NumStorePurchases`-`NumWebVisitsMonth`-`AcceptedCmp1`-`AcceptedCmp5`-`target`

- `NumDealsPurchases`-`Teenhome`


#### **High Cardinality**

`Dt_customer`

  - â†ª ê³ ê°ì´ íšŒì‚¬ì— ë“±ë¡í•œ ë‚ ì§œë¥¼ ì˜ë¯¸í•˜ê¸° ë•Œë¬¸ì— ì¤‘ë³µë„ê°€ ë‚®ì€ ë°ì´í„°ì…ë‹ˆë‹¤.

--------------------------------

ğŸ“ Cardinalityê°€ ë†’ë‹¤ <-> ì¤‘ë³µë˜ëŠ” ê°’ì´ ì ë‹¤


## 2. EDA | Exploratory Data Analysis

- `id` : ìƒ˜í”Œ ì•„ì´ë””, `Year_Birth` : ê³ ê° ìƒë…„ì›”ì¼, `Education` : ê³ ê° í•™ë ¥

- `Marital_status` : ê³ ê° ê²°í˜¼ ìƒíƒœ, `Income` : ê³ ê° ì—°ê°„ ê°€êµ¬ ì†Œë“

- `Kidhome` : ê³ ê° ê°€êµ¬ì˜ ìë…€ ìˆ˜, `Teenhome` : ê³ ê° ê°€êµ¬ì˜ ì²­ì†Œë…„ ìˆ˜, `Dt_Customer` : ê³ ê°ì´ íšŒì‚¬ì— ë“±ë¡í•œ ë‚ ì§œ

- `Recency` : ê³ ê°ì˜ ë§ˆì§€ë§‰ êµ¬ë§¤ ì´í›„ ì¼ìˆ˜, `NumDealsPurchases` : í• ì¸ëœ êµ¬ë§¤ íšŸìˆ˜, `NumWebPurchases` : íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ë¥¼ í†µí•œ êµ¬ë§¤ ê±´ìˆ˜

- `NumCatalogPurchases` : ì¹´íƒˆë¡œê·¸ë¥¼ ì‚¬ìš©í•œ êµ¬ë§¤ ìˆ˜, `NumStorePuchases` : ë§¤ì¥ì—ì„œ ì§ì ‘ êµ¬ë§¤í•œ íšŸìˆ˜

- `NumWebVisitsMonth` : ì§€ë‚œ ë‹¬ íšŒì‚¬ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸ íšŸìˆ˜

- `AcceptedCmp(1-5)` : ê³ ê°ì´ (1-5) ë²ˆì§¸ ìº í˜ì¸ì—ì„œ ì œì•ˆì„ ìˆ˜ë½í•œ ê²½ìš° 1, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° 0

- `Complain` : ê³ ê°ì´ ì§€ë‚œ 2ë…„ ë™ì•ˆ ë¶ˆë§Œì„ ì œê¸°í•œ ê²½ìš° 1, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° 0

- `Response` : ê³ ê°ì´ ë§ˆì§€ë§‰ ìº í˜ì¸ì—ì„œ ì œì•ˆì„ ìˆ˜ë½í•œ ê²½ìš° 1, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° 0

- `target` : ê³ ê°ì˜ ì œí’ˆ ì´ ì†Œë¹„ëŸ‰



---------------------
### **Data Type**

- Numeric (10) : `id`, `Year_Birth`, `Income`, `Recency`, `NumDealsPurchases`, `NumWebPurchases`, `NumCatalogPurchases`, `NumStorePurchases`, `NumWebVisitsMonth`, `target`

- Categorical (12) : `Education`, `Marital_Status`, `Kidhome`, `Teenhome`, `Dt_Customer`, `AcceptedCmp(1~5)`, `Complain`, `Response`

---------------------

ğŸ“ ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.



```python
train.isnull().sum()
```

<pre>
id                     0
Year_Birth             0
Education              0
Marital_Status         0
Income                 0
Kidhome                0
Teenhome               0
Dt_Customer            0
Recency                0
NumDealsPurchases      0
NumWebPurchases        0
NumCatalogPurchases    0
NumStorePurchases      0
NumWebVisitsMonth      0
AcceptedCmp3           0
AcceptedCmp4           0
AcceptedCmp5           0
AcceptedCmp1           0
AcceptedCmp2           0
Complain               0
Response               0
target                 0
dtype: int64
</pre>

```python
test.isnull().sum()
```

<pre>
id                     0
Year_Birth             0
Education              0
Marital_Status         0
Income                 0
Kidhome                0
Teenhome               0
Dt_Customer            0
Recency                0
NumDealsPurchases      0
NumWebPurchases        0
NumCatalogPurchases    0
NumStorePurchases      0
NumWebVisitsMonth      0
AcceptedCmp3           0
AcceptedCmp4           0
AcceptedCmp5           0
AcceptedCmp1           0
AcceptedCmp2           0
Complain               0
Response               0
dtype: int64
</pre>

```python
df_train = train.copy()
df_test = test.copy()
```

#### **2-(1). Outliers**

- ğŸ“ `id`ì™€ `target`ì„ ì œì™¸í•œ numerical ë°ì´í„°ì˜ outlier ë“¤ì„ IQR methodë¥¼ í™œìš©í•˜ì—¬ ì°¾ì•„ì¤ë‹ˆë‹¤.



```python
numeric_fts = ['Year_Birth', 'Income', 'Recency', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth']

train_outlier_ind = []
for i in numeric_fts:
  Q1 = np.percentile(df_train[i],25)
  Q3 = np.percentile(df_train[i],75)
  IQR = Q3-Q1
  train_outlier_list = df_train[(df_train[i] < Q1 - IQR * 1.5) | (df_train[i] > Q3 + IQR * 1.5)].index
  train_outlier_ind.extend(train_outlier_list)

train_outlier_ind = Counter(train_outlier_ind)
train_multi_outliers = list(k for k,j in train_outlier_ind.items() if j > 2)  

print("The number of train outliers :", len(train_multi_outliers))
```

<pre>
The number of train outliers : 0
</pre>

ğŸ“ Train ë°ì´í„°ì—ëŠ” IQR methodë¡œ íƒì§€ë˜ëŠ” ì´ìƒì¹˜ê°€ ì—†ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


#### **2-(2). Transformation**

ğŸ“ ì™œê³¡ëœ ë¶„í¬ëŠ” ëª¨ë¸ í•™ìŠµì— ì•ˆì¢‹ì€ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë†’ì€ skewnessë¥¼ ê°€ì§€ê³  ìˆëŠ” `NumDealsPurchases` ë³€ìˆ˜ì— ëŒ€í•˜ì—¬ ëª‡ê°€ì§€ transformationì„ ì§„í–‰í•˜ë ¤í•©ë‹ˆë‹¤.



```python
print(df_train[numeric_fts].skew())
```

<pre>
Year_Birth            -0.439100
Income                 0.291634
Recency               -0.061310
NumDealsPurchases      2.264245
NumWebPurchases        1.289607
NumCatalogPurchases    1.099499
NumStorePurchases      0.653689
NumWebVisitsMonth      0.299000
dtype: float64
</pre>

```python
fig = plt.figure(figsize = (16,6))
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)

sns.distplot(df_train['NumDealsPurchases'], ax = ax1, label='Skewness : {:.2f}'.format(df_train['NumDealsPurchases'].skew()))
ax1.legend(loc='best', fontsize = 15)

stats.probplot(df_train['NumDealsPurchases'], plot = ax2)
plt.title("Q-Q Plot", fontsize = 15)
plt.show()
```

![dist](/assets/img/for_post/20220506-2.png)

#### **Log transformation**


```python
log_trans = df_train['NumDealsPurchases'].map(lambda i: np.log(i) if i > 0 else 0)

fig = plt.figure(figsize = (16,6))
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)

sns.distplot(log_trans, ax = ax1, color='crimson', label='Skewness : {:.2f}'.format(log_trans.skew()))
ax1.legend(loc='best', fontsize = 15)
ax1.set_title('Log transformation', fontsize = 15)

stats.probplot(log_trans, plot = ax2)
ax2.set_title("Q-Q Plot", fontsize = 15)
plt.show()
```

![log_dist](/assets/img/for_post/20220506-3.png)

#### **Yeo-Johnson transformation**

```python
jy = PowerTransformer(method = 'yeo-johnson')
jy.fit(df_train['NumDealsPurchases'].values.reshape(-1, 1))
x_yj = jy.transform(df_train['NumDealsPurchases'].values.reshape(-1, 1))

fig = plt.figure(figsize = (16,6))
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)

sns.distplot(x_yj, ax = ax1, color='crimson', label='Skewness : {:.5f}'.format(np.float(stats.skew(x_yj))))
ax1.legend(loc='best', fontsize = 15)
ax1.set_title('Yeo-Johnson transformation', fontsize = 15)

stats.probplot(x_yj.reshape(x_yj.shape[0]), plot = ax2)
ax2.legend(['Lambda : {:.2f}'.format(np.float(jy.lambdas_))], loc='best', fontsize = 15)
ax2.set_title("Q-Q Plot", fontsize = 15)
plt.show()
```

![yeo_dist](/assets/img/for_post/20220506-4.png)

ğŸ“ ë‘ ë³€í™˜ì„ ì§„í–‰í•œ ê²°ê³¼ ëª¨ë‘ ì¡°ê¸ˆ ë” ì •ê·œë¶„í¬ ì§ì„ ê³¼ ë¹„ìŠ·í•´ì§„ê²ƒì„ Q-Q Plotì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ“ ë°ì´í„° ì „ì²˜ë¦¬ì—ëŠ” Yeo-Johnson transformationì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.



```python
df_train['NumDealsPurchases'] = x_yj
df_train['NumDealsPurchases'].head()
```

<pre>
0    2.258975
1   -0.801066
2    0.146388
3    0.146388
4    1.846930
Name: NumDealsPurchases, dtype: float64
</pre>

```python
test_jy = PowerTransformer(method = 'yeo-johnson')
test_jy.fit(df_test['NumDealsPurchases'].values.reshape(-1, 1))
test_x_yj = test_jy.transform(df_test['NumDealsPurchases'].values.reshape(-1, 1))
df_test['NumDealsPurchases'] = test_x_yj
```

### **2-(3). Correlation**

ğŸ“ ì•ì„œ ìˆ˜í–‰í•œ pandas profiling reportì˜ alertë¥¼ ì°¸ê³ í•˜ì—¬ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.



```python
corr_fts1 = ['Income', 'Kidhome', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'AcceptedCmp1', 'AcceptedCmp5', 'target']
corr_fts2 = ['NumDealsPurchases', 'Teenhome']
```


```python
plt.figure(figsize = (10,8))
sns.heatmap(df_train[corr_fts1].corr(), annot=True)

plt.show()
```

![corr1](/assets/img/for_post/20220506-5.png)

```python
plt.figure(figsize = (8,6))
sns.heatmap(df_train[corr_fts2].corr(), annot=True)

plt.show()
```

![corr2](/assets/img/for_post/20220506-6.png)

ğŸ“ ë…ë¦½ë³€ìˆ˜ ê°„ì˜ ë†’ì€ ìƒê´€ê´€ê³„ëŠ” ë‹¤ì¤‘ê³µì„ ì„±ì„ ìœ ë°œí•˜ê¸° ë•Œë¬¸ì— ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤.

ğŸ“ ìœ„ ë¬¸ì œëŠ” ë³€ìˆ˜ ì„ íƒ, ì°¨ì› ì¶•ì†Œ, ê·œì œ ë“±ì˜ ë°©ë²•ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆê³ , ì €ëŠ” ëª¨ë¸ì— ê·œì œë¥¼ ì ìš©í•˜ê±°ë‚˜ ë‹¤ì¤‘ê³µì„ ì„±ì˜ ì˜í–¥ì„ ì ê²Œ ë°›ëŠ”ë‹¤ê³  ìƒê°ë˜ëŠ” Decision Tree ë² ì´ìŠ¤ì˜ ëª¨ë¸ì„ ì‚¬ìš© í•  ì˜ˆì •ì…ë‹ˆë‹¤.



```python
train_dataset = df_train.copy()
test_dataset = df_test.copy()
```

## **3. Feature Engineering**


#### **3-(1) `Dt_Customer` ë³€ìˆ˜ : ë‚ ì§œ ë°ì´í„° ë‹¤ë£¨ê¸°**

ğŸ“ `Dt_Customer` ë³€ìˆ˜ëŠ” íšŒì‚¬ ë“±ë¡ì¼ì„ ëœ»í•©ë‹ˆë‹¤. íšŒì‚¬ì— ë“±ë¡í•œ ì‹œì ì— ëŒ€í•œ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ëª¨ë¸ë§ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ë§Œë“¤ë ¤ê³ í•©ë‹ˆë‹¤.  

â†ª ê°€ì¥ ê³¼ê±° ì‹œì ì˜ íšŒì‚¬ ë“±ë¡ì¼ë¡œë¶€í„° ë©°ì¹ ì´ ì§€ë‚¬ëŠ”ì§€ë¥¼ ëœ»í•˜ëŠ” `Pass_Customer`ë³€ìˆ˜ë¥¼ ìƒˆë¡­ê²Œ ìƒì„±í•©ë‹ˆë‹¤. 


```python
train_dataset["Dt_Customer"]
```

<pre>
0       21-01-2013
1       24-05-2014
2       08-04-2013
3       29-03-2014
4       10-06-2014
           ...    
1103    31-03-2013
1104    21-10-2013
1105    16-12-2013
1106    30-05-2013
1107    29-10-2012
Name: Dt_Customer, Length: 1108, dtype: object
</pre>

```python
train_dataset["Dt_Customer"] = pd.to_datetime(train_dataset["Dt_Customer"], format='%d-%m-%Y')
test_dataset["Dt_Customer"] = pd.to_datetime(test_dataset["Dt_Customer"], format='%d-%m-%Y')

train_dataset["Dt_Customer"]
```

<pre>
0      2013-01-21
1      2014-05-24
2      2013-04-08
3      2014-03-29
4      2014-06-10
          ...    
1103   2013-03-31
1104   2013-10-21
1105   2013-12-16
1106   2013-05-30
1107   2012-10-29
Name: Dt_Customer, Length: 1108, dtype: datetime64[ns]
</pre>

```python
print(f'Minimum date: {train_dataset["Dt_Customer"].min()}')
print(f'Maximum date: {train_dataset["Dt_Customer"].max()}')
```

<pre>
Minimum date: 2012-07-31 00:00:00
Maximum date: 2014-06-29 00:00:00
</pre>

```python
train_diff_date = train_dataset["Dt_Customer"] - train_dataset["Dt_Customer"].min()
test_diff_date = test_dataset["Dt_Customer"] - test_dataset["Dt_Customer"].min()

train_dataset["Pass_Customer"] = [i.days for i in train_diff_date]
test_dataset["Pass_Customer"] = [i.days for i in test_diff_date]
```


```python
train_dataset["Pass_Customer"].head()
```

<pre>
0    174
1    662
2    251
3    606
4    679
Name: Pass_Customer, dtype: int64
</pre>

#### **3-(2) `Year_Birth` to `Age`**

- ğŸ“ `Year_Birth` ë³€ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ê³ ê°ì˜ ë‚˜ì´ë¥¼ ëœ»í•˜ëŠ” `Age` ë³€ìˆ˜ë¥¼ ìƒˆë¡­ê²Œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.

- ğŸ“ í•œêµ­ë‚˜ì´ë¡œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤.



```python
print("Minimum birth :", train_dataset["Year_Birth"].min(), "\nMaximum birth :", train_dataset["Year_Birth"].max(), "\n")
train_dataset["Year_Birth"].head()
```

<pre>
Minimum birth : 1893 
Maximum birth : 1996 

</pre>
<pre>
0    1974
1    1962
2    1951
3    1974
4    1946
Name: Year_Birth, dtype: int64
</pre>

```python
train_dataset["Age"] = 2022 - train_dataset["Year_Birth"] + 1
test_dataset["Age"] = 2022 - test_dataset["Year_Birth"] + 1

train_dataset["Age"].head()
```

<pre>
0    49
1    61
2    72
3    49
4    77
Name: Age, dtype: int64
</pre>

#### **3-(3) `AcceptedCmp(1~5)` ì™€ `Response` ë³€ìˆ˜ë¡œ ìƒˆ Feature ìƒì„±**

ğŸ“ ìœ„ ì—¬ì„¯ê°œì˜ ë³€ìˆ˜ëŠ” ê³ ê°ì´ 1~5 ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ìº í˜ì¸ì—ì„œ ì œì•ˆì„ ìˆ˜ë½í•œ ê²½ìš° 1, ì•„ë‹Œê²½ìš° 0 ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.  
ğŸ“ ì´ ë³€ìˆ˜ë“¤ì„ í™œìš©í•˜ì—¬ ìº í˜ì¸ì—ì„œ ì œì•ˆì„ ìˆ˜ë½í•œ íšŸìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” `AcceptCount` ë³€ìˆ˜ë¥¼ ìƒˆë¡­ê²Œ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.  



```python
train_dataset["AcceptCount"] = train_dataset["AcceptedCmp1"] + train_dataset["AcceptedCmp2"] + train_dataset["AcceptedCmp3"] + train_dataset["AcceptedCmp4"] + train_dataset["AcceptedCmp5"] + train_dataset["Response"]
test_dataset["AcceptCount"] = test_dataset["AcceptedCmp1"] + test_dataset["AcceptedCmp2"] + test_dataset["AcceptedCmp3"] + test_dataset["AcceptedCmp4"] + test_dataset["AcceptedCmp5"] + test_dataset["Response"]

train_dataset["AcceptCount"].head()
```

<pre>
0    0
1    1
2    0
3    0
4    1
Name: AcceptCount, dtype: int64
</pre>

```python
print("Minimum count :", train_dataset["AcceptCount"].min(), "\nMaximum count :", train_dataset["AcceptCount"].max(), "\n")
```

<pre>
Minimum count : 0 
Maximum count : 5 

</pre>

ğŸ“ train ë°ì´í„°ì—ì„œ ìº í˜ì¸ ì œì•ˆì„ ì—¬ì„¯ë²ˆ ëª¨ë‘ ìˆ˜ë½í•œ ê²½ìš°ëŠ” ì—†ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ğŸ“ ì›ë˜ì˜ ë³€ìˆ˜ì™€ `target`ê³¼ì˜ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.  



```python
train_dataset[['Year_Birth', 'AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5', 'Response','target']].corr()
```

<pre>
              Year_Birth  AcceptedCmp1  AcceptedCmp2  AcceptedCmp3  \
Year_Birth      1.000000     -0.050053     -0.034204      0.066802   
AcceptedCmp1   -0.050053      1.000000      0.198530      0.052213   
AcceptedCmp2   -0.034204      0.198530      1.000000      0.052513   
AcceptedCmp3    0.066802      0.052213      0.052513      1.000000   
AcceptedCmp4   -0.111485      0.184717      0.328941     -0.083690   
AcceptedCmp5   -0.010873      0.379563      0.192139      0.060890   
Response       -0.012304      0.268577      0.201945      0.194275   
target         -0.136035      0.361102      0.129995      0.040736   

              AcceptedCmp4  AcceptedCmp5  Response    target  
Year_Birth       -0.111485     -0.010873 -0.012304 -0.136035  
AcceptedCmp1      0.184717      0.379563  0.268577  0.361102  
AcceptedCmp2      0.328941      0.192139  0.201945  0.129995  
AcceptedCmp3     -0.083690      0.060890  0.194275  0.040736  
AcceptedCmp4      1.000000      0.313120  0.189849  0.256784  
AcceptedCmp5      0.313120      1.000000  0.336610  0.458208  
Response          0.189849      0.336610  1.000000  0.242760  
target            0.256784      0.458208  0.242760  1.000000  
</pre>

```python
# Dt_customer
year = pd.to_datetime(train_dataset["Dt_Customer"]).dt.year
month = pd.to_datetime(train_dataset["Dt_Customer"]).dt.month
day = pd.to_datetime(train_dataset["Dt_Customer"]).dt.day

print(np.corrcoef(year, train_dataset['target']), '\n')
print(np.corrcoef(month, train_dataset['target']), '\n')
print(np.corrcoef(day, train_dataset['target']))
```

<pre>
[[ 1.         -0.15940385]
 [-0.15940385  1.        ]] 

[[1.         0.03764911]
 [0.03764911 1.        ]] 

[[1.         0.01891694]
 [0.01891694 1.        ]]
</pre>
ğŸ“ ìƒˆë¡œ ìƒì„±í•œ ë³€ìˆ˜ì™€ `target`ê³¼ì˜ ìƒê´€ê´€ê³„ë¥¼ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.  



```python
train_dataset[['Pass_Customer', 'Age', 'AcceptCount', 'target']].corr()
```

<pre>
               Pass_Customer       Age  AcceptCount    target
Pass_Customer       1.000000  0.012309    -0.080152 -0.174969
Age                 0.012309  1.000000     0.043180  0.136035
AcceptCount        -0.080152  0.043180     1.000000  0.444114
target             -0.174969  0.136035     0.444114  1.000000
</pre>
ğŸ“ ì •ë¦¬í•˜ìë©´, `Pass_Customer`-`target`ì˜ ìƒê´€ê³„ìˆ˜ ì ˆëŒ“ê°’ì´ `Dt_Customer`(`year`, `month`, `day`)-`target` ë³´ë‹¤ ì¡°ê¸ˆ ë” í¬ë‹¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

ğŸ“ ë˜í•œ, ë‹¹ì—°í•˜ê²Œë„ `Year_Birth`ë¥¼ `Age` ë³€ìˆ˜ë¡œ ë°”ê¾¼ê²ƒì€ ìƒê´€ê´€ê³„ì— ì•„ë¬´ëŸ° ì˜í–¥ë„ ì£¼ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.  

ğŸ“ `AcceptCount`ëŠ” `target`ê³¼ ì–´ëŠì •ë„ ìƒê´€ê´€ê³„ê°€ ìˆìŠµë‹ˆë‹¤.  




```python
train_data = train_dataset.copy()
test_data = test_dataset.copy()
```

## **4. One-Hot Encoding**

ğŸ“ `Education`, `Marital_Status` ë³€ìˆ˜ì˜ one-hot encodingì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  



```python
drop_col = ['id', 'Dt_Customer', 'Year_Birth', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']

train_data = train_data.drop(drop_col, axis = 1)
test_data = test_data.drop(drop_col, axis = 1)
```


```python
print(train_data['Education'].unique())
print(train_data['Marital_Status'].unique())
```

<pre>
['Master' 'Graduation' 'Basic' 'PhD' '2n Cycle']
['Together' 'Single' 'Married' 'Widow' 'Divorced' 'Alone' 'YOLO' 'Absurd']
</pre>

```python
# One-hot encoding
train_data = pd.get_dummies(train_data)
test_data = pd.get_dummies(test_data)

print(train_data.columns)
print(test_data.columns)
```

<pre>
Index(['Income', 'Kidhome', 'Teenhome', 'Recency', 'NumDealsPurchases',
       'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',
       'NumWebVisitsMonth', 'Complain', 'target', 'Pass_Customer', 'Age',
       'AcceptCount', 'Education_2n Cycle', 'Education_Basic',
       'Education_Graduation', 'Education_Master', 'Education_PhD',
       'Marital_Status_Absurd', 'Marital_Status_Alone',
       'Marital_Status_Divorced', 'Marital_Status_Married',
       'Marital_Status_Single', 'Marital_Status_Together',
       'Marital_Status_Widow', 'Marital_Status_YOLO'],
      dtype='object')
Index(['Income', 'Kidhome', 'Teenhome', 'Recency', 'NumDealsPurchases',
       'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases',
       'NumWebVisitsMonth', 'Complain', 'Pass_Customer', 'Age', 'AcceptCount',
       'Education_2n Cycle', 'Education_Basic', 'Education_Graduation',
       'Education_Master', 'Education_PhD', 'Marital_Status_Absurd',
       'Marital_Status_Alone', 'Marital_Status_Divorced',
       'Marital_Status_Married', 'Marital_Status_Single',
       'Marital_Status_Together', 'Marital_Status_Widow',
       'Marital_Status_YOLO'],
      dtype='object')
</pre>

```python
print("Length of train column :", len(train_data.columns))
print("Length of test column :", len(test_data.columns))
```

<pre>
Length of train column : 27
Length of test column : 26
</pre>

ğŸ“ train ë°ì´í„°ì˜ `target` ì»¬ëŸ¼ì„ ì œì™¸í•˜ê³ ëŠ” trainê³¼ testì˜ ì—´ê¸¸ì´ê°€ ê°™ë„ë¡ one-hot encodingì´ ì˜ ì§„í–‰ëœê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  



```python
train_data.head()
```

<pre>
    Income  Kidhome  Teenhome  Recency  NumDealsPurchases  NumWebPurchases  \
0  46014.0        1         1       21           2.258975                7   
1  76624.0        0         1       68          -0.801066                5   
2  75903.0        0         1       50           0.146388                6   
3  18393.0        1         0        2           0.146388                3   
4  64014.0        2         1       56           1.846930                8   

   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  Complain  ...  \
0                    1                  8                  7         0  ...   
1                   10                  7                  1         0  ...   
2                    6                  9                  3         0  ...   
3                    0                  3                  8         0  ...   
4                    2                  5                  7         0  ...   

   Education_Master  Education_PhD  Marital_Status_Absurd  \
0                 1              0                      0   
1                 0              0                      0   
2                 0              0                      0   
3                 0              0                      0   
4                 0              1                      0   

   Marital_Status_Alone  Marital_Status_Divorced  Marital_Status_Married  \
0                     0                        0                       0   
1                     0                        0                       0   
2                     0                        0                       1   
3                     0                        0                       1   
4                     0                        0                       0   

   Marital_Status_Single  Marital_Status_Together  Marital_Status_Widow  \
0                      0                        1                     0   
1                      1                        0                     0   
2                      0                        0                     0   
3                      0                        0                     0   
4                      0                        1                     0   

   Marital_Status_YOLO  
0                    0  
1                    0  
2                    0  
3                    0  
4                    0  

[5 rows x 27 columns]
</pre>
## **5. Modeling**

ğŸ“ train x ë°ì´í„°ì™€ target ë°ì´í„°ë¥¼ ë‚˜ëˆ ì¤ë‹ˆë‹¤.  



```python
train_x = train_data.drop('target', axis = 1)
train_y = pd.DataFrame(train_data['target'])
```


```python
def nmae(true, pred):
    mae = np.mean(np.abs(true-pred))
    score = mae / np.mean(np.abs(true))
    return score
```

ğŸ“ Lasso, Ridge regressionì€ Linear regressionì— ê·œì œë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ì €ëŠ” ì´ ë‘ ëª¨ë¸ì˜ ê·œì œë¥¼ ëª¨ë‘ ì ìš©í•  ìˆ˜ ìˆëŠ” **Elastic-Net**ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.  

ğŸ“ ë˜í•œ **LightGBM, XGBoost** ëª¨ë¸ì„ ì‚¬ìš©í–ˆê³ , ìµœì¢…ì ìœ¼ë¡œ ì„¸ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ **Ensemble**ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  


### **Elastic-Net**



```python
ela_param_grid = {'alpha': np.arange(1e-4,1e-3,1e-4),
              'l1_ratio': np.arange(0.1,1.0,0.1),
              'max_iter':[100000]}

elasticnet = ElasticNet(random_state = seed_num)

ela_rkfold = RepeatedKFold(n_splits = 5, n_repeats = 5, random_state = seed_num)
ela_gsearch = GridSearchCV(elasticnet, ela_param_grid, cv = ela_rkfold, scoring='neg_mean_absolute_error',
                               verbose=1, return_train_score=True)
```


```python
ela_gsearch.fit(train_x, train_y)
```

<pre>
Fitting 25 folds for each of 81 candidates, totalling 2025 fits
</pre>
<pre>
GridSearchCV(cv=RepeatedKFold(n_repeats=5, n_splits=5, random_state=42),
             estimator=ElasticNet(random_state=42),
             param_grid={'alpha': array([0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008,
       0.0009]),
                         'l1_ratio': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),
                         'max_iter': [100000]},
             return_train_score=True, scoring='neg_mean_absolute_error',
             verbose=1)
</pre>

```python
elasticnet = ela_gsearch.best_estimator_        
ela_grid_results = pd.DataFrame(ela_gsearch.cv_results_)  
ela_pred = elasticnet.predict(train_x)
```


```python
print("train nmae of elasticnet :", nmae(train_y.values, ela_pred))
```

<pre>
train nmae of elasticnet : 1.0457572302381468
</pre>
### **XGBoost**



```python
xgb = XGBRegressor(objective='reg:squarederror', random_state = seed_num)

xgb_param_grid = {'n_estimators':np.arange(100,500,100),
              'max_depth':[1,2,3],
             }

xgb_rkfold = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = seed_num)
xgb_gsearch = GridSearchCV(xgb, xgb_param_grid, cv = xgb_rkfold, scoring='neg_mean_absolute_error',
                               verbose=1, return_train_score=True)
```


```python
xgb_gsearch.fit(train_x, train_y)
```

<pre>
Fitting 5 folds for each of 12 candidates, totalling 60 fits
</pre>
<pre>
GridSearchCV(cv=RepeatedKFold(n_repeats=1, n_splits=5, random_state=42),
             estimator=XGBRegressor(objective='reg:squarederror',
                                    random_state=42),
             param_grid={'max_depth': [1, 2, 3],
                         'n_estimators': array([100, 200, 300, 400])},
             return_train_score=True, scoring='neg_mean_absolute_error',
             verbose=1)
</pre>

```python
xgb = xgb_gsearch.best_estimator_        
xgb_grid_results = pd.DataFrame(xgb_gsearch.cv_results_)  
xgb_pred = xgb.predict(train_x)

print("train nmae of xgb :", nmae(train_y.values, xgb_pred))
```

<pre>
train nmae of xgb : 1.0603134393578721
</pre>
### **LightGBM**



```python
lgbm = LGBMRegressor(objective='regression', random_state = seed_num)

lgbm_param_grid = {'n_estimators': [8,16,24], 'num_leaves': [6,8,12,16], 'reg_alpha' : [1,1.2], 'reg_lambda' : [1,1.2,1.4]}


lgbm_rkfold = RepeatedKFold(n_splits = 5, n_repeats = 1, random_state = seed_num)
lgbm_gsearch = GridSearchCV(lgbm, lgbm_param_grid, cv = lgbm_rkfold, scoring='neg_mean_absolute_error',
                               verbose=1, return_train_score=True)
```


```python
lgbm_gsearch.fit(train_x, train_y)
```

<pre>
Fitting 5 folds for each of 72 candidates, totalling 360 fits
</pre>
<pre>
GridSearchCV(cv=RepeatedKFold(n_repeats=1, n_splits=5, random_state=42),
             estimator=LGBMRegressor(objective='regression', random_state=42),
             param_grid={'n_estimators': [8, 16, 24],
                         'num_leaves': [6, 8, 12, 16], 'reg_alpha': [1, 1.2],
                         'reg_lambda': [1, 1.2, 1.4]},
             return_train_score=True, scoring='neg_mean_absolute_error',
             verbose=1)
</pre>

```python
lgbm = lgbm_gsearch.best_estimator_        
lgbm_grid_results = pd.DataFrame(lgbm_gsearch.cv_results_)  
lgbm_pred = lgbm.predict(train_x)

print("train nmae of lgbm :", nmae(train_y.values, lgbm_pred))
```

<pre>
train nmae of lgbm : 1.0075199760582296
</pre>
### **Blending Models - Ensemble**



```python
def blended_models(X):
    return ((elasticnet.predict(X)) + (xgb.predict(X)) + (lgbm.predict(X)))/3
```


```python
blended_score = nmae(train_y.values, blended_models(train_x))
print('train nmae of blended model:', blended_score)
```

<pre>
train nmae of blended model: 1.0298941681188711
</pre>


--------------------------

ê°ì‚¬í•©ë‹ˆë‹¤ :)  
ë„ì›€ì´ ëê¸¸ ë°”ëë‹ˆë‹¤ğŸ‘ğŸ‘

