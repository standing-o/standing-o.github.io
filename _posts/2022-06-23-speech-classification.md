---
title: "ìŒì„± ë°ì´í„° ë¶„ë¥˜í•˜ê¸° | ë°ì´ì½˜"
date: 2022-06-23 17:00:00 +/-TTTT
categories: [ë¦¬ë·°, ëŒ€íšŒ]
tags: [dacon, ai-competition, python, deep-learning, classification, feature-engineering, spectrogram, fourier-transform, mfcc, melspectrogram, speech]
math: true
toc: true
author: seoyoung
img_path: /assets/img/for_post/
description: ğŸ“¢ ìŒì„± ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ë°ì´í„° ì¦ê°• ê¸°ë²•ê³¼ Feature Engineeringì„ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ê³µìœ í•©ë‹ˆë‹¤.
---

------------------
> **<u>KEYWORDS</u>**    
> ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬, ìŒì„± ë°ì´í„° ë”¥ëŸ¬ë‹, ìŒì„± ë°ì´í„° ì¦ê°•, ìŒì„± ë°ì´í„° ë¶„ì„, ìŒì„± ë°ì´í„° ë¶„ë¥˜, Audio Feature Extraction
{: .prompt-info }
------------------

&nbsp;
&nbsp;
&nbsp;


ë°ì´ì½˜ì˜ "ìŒì„± ë¶„ë¥˜ ê²½ì§„ëŒ€íšŒ"ì— ì°¸ì—¬í•˜ì—¬ ì‘ì„±í•œ ê¸€ì´ë©°, ì½”ë“œì‹¤í–‰ì€ Google Colabì˜ CPU, Standard RAM í™˜ê²½ì—ì„œ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.  

â” [ë°ì´ì½˜ì—ì„œ ì½ê¸°](https://dacon.io/competitions/official/235905/codeshare/5209)

&nbsp;
&nbsp;
&nbsp;

## **0. Import Packages**
- ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

```python
import numpy as np
import pandas as pd
import random as rn
import os

from scipy.io import wavfile
import librosa

import matplotlib.pyplot as plt
import seaborn as sns
import IPython.display as ipd
import librosa.display

import warnings
warnings.filterwarnings("ignore")
%matplotlib inline
```

&nbsp;
&nbsp;
&nbsp;

## **1. Load and explore dataset**
- ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° 

```python
train = pd.read_csv('/content/drive/MyDrive/Speech_classification/train.csv')
test = pd.read_csv('/content/drive/MyDrive/Speech_classification/test.csv')
```

&nbsp;
&nbsp;
&nbsp;

- í•œ ìŒì„±ì˜ Waveplotì„ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.



```python
a_filename = '/content/drive/MyDrive/Speech_classification/dataset/train/001.wav'
samples, sample_rate = librosa.load(a_filename)

plt.figure(figsize=(10, 7))

# plt.plot(np.linspace(0, sample_rate/len(samples), len(samples)), samples)
librosa.display.waveplot(samples, sr=40000)

plt.xlabel('time', fontsize = 14)
plt.ylabel('amplitude', fontsize = 14)
plt.title('001.wav | Length : ' + str(len(samples)))

plt.show()
```

![waveplot](20220623-1.png)

&nbsp;
&nbsp;
&nbsp;

```python
print(sample_rate)
print(samples)
```

<pre>
    22050
    [0.00013066 0.00016804 0.00014106 ... 0.00017342 0.00017514 0.        ]
</pre>

&nbsp;
&nbsp;
&nbsp;

- í•œ ìŒì„± ìƒ˜í”Œì— ëŒ€í•œ Spectrogramì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.  
â†ª Short term Fourier transform (STFT)ì˜ Magnitudeë¥¼ DB-ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ Spectrogramì„ ìƒì„±í•©ë‹ˆë‹¤.



```python
samples, sample_rate = librosa.load(a_filename)
X = librosa.stft(samples)  # data -> short term FT
Xdb = librosa.amplitude_to_db(abs(X))

plt.figure(figsize=(12, 3))
plt.title('001.wav spectrogram | Length : ' + str(len(samples)))
librosa.display.specshow(Xdb, sr = sample_rate, x_axis='time', y_axis='hz')   
plt.colorbar()
plt.show()
```

![spectrogram](20220623-2.png)


&nbsp;
&nbsp;
&nbsp;

- `train.csv`ì—ëŠ” `train` í´ë”ì— ìœ„ì¹˜í•œ ìŒì„± íŒŒì¼ë“¤ì˜ ì´ë¦„ê³¼ ë¼ë²¨ ì»¬ëŸ¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. `label` ì»¬ëŸ¼ì€ 0ê³¼ 9ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

```python
train.head()
```

<pre>
      file_name  label
    0   001.wav      9
    1   002.wav      0
    2   004.wav      1
    3   005.wav      8
    4   006.wav      0
</pre>

```python
print(train['label'].unique())
```

<pre>
    [9 0 1 8 7 4 5 2 6 3]
</pre>

&nbsp;
&nbsp;
&nbsp;

- ë°ì´í„°ê°€ í´ë˜ìŠ¤ ê· í˜•ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

```python
plt.figure(figsize=(12, 8))
sns.countplot(train['label'])

plt.title("The number of recordings for each label")
plt.ylabel("Count", fontsize = 14)
plt.xlabel("Label", fontsize = 14)
plt.show()
```

![count](20220623-3.png)

```python
file_name = train['file_name']
train_path = '/content/drive/MyDrive/Speech_classification/dataset/train/'
```

&nbsp;
&nbsp;
&nbsp;

- ë°ì´í„°ë“¤ì˜ ê¸¸ì´ê°€ ëª¨ë‘ ë‹¤ë¦…ë‹ˆë‹¤.

```python
all_shape = []
for f in file_name:
  data, sample_rate = librosa.load(train_path + f, sr = 20000)
  all_shape.append(data.shape)

print(all_shape[:5])
print("Max :", np.max(all_shape, axis = 0))
print("Min :", np.min(all_shape, axis = 0))
```

<pre>
    [(12740,), (13126,), (12910,), (9753,), (17572,)]
    Max : [19466]
    Min : [7139]
</pre>

&nbsp;
&nbsp;
&nbsp;

## **2. Data Augmentation**

- ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ í–¥ìƒì„ ìœ„í•´, ê¸°ì¡´ì˜ ìŒì„±ë°ì´í„°ì— Perturbationì„ ì¶”ê°€í•˜ì—¬ ìƒˆ ìŒì„±ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

â†ª Noise ì¶”ê°€, Time Stretching, Pitch ë³€í™˜


```python
# noise ì¶”ê°€
def noise(sample):
    noise_amp = 0.01*np.random.uniform()*np.amax(sample)
    sample = sample + noise_amp*np.random.normal(size = sample.shape[0])
    return sample

# time stretching
def stretch(sample, rate = 0.8):
    stretch_sample = librosa.effects.time_stretch(sample, rate)
    return stretch_sample

# pitch ë³€í™˜
def pitch(sample, sampling_rate, pitch_factor = 0.8):
    pitch_sample = librosa.effects.pitch_shift(sample, sampling_rate, pitch_factor)
    return pitch_sample
```

&nbsp;
&nbsp;
&nbsp;

## **3. Feature Extraction**

- ëª¨ë¸ë§ì— ì‚¬ìš©í•  ë§Œí•œ ëª‡ê°€ì§€ Feature Extraction ë°©ë²•ì„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

#### (1) ZCR <sup>Zero Crossing Rate</sup>

â†ª íŠ¹ì • í”„ë ˆì„ì—ì„œ ì‹ í˜¸ì˜ ë¶€í˜¸(Sign)ê°€ ë³€ê²½ë˜ëŠ” ë¹ˆë„ì…ë‹ˆë‹¤. (i.e., ì‹ í˜¸ì˜ ë¶€í˜¸ ë³€í™”ìœ¨)

#### (2) Chroma Shift

â†ª íŒŒí˜•(Waveform) ë˜ëŠ” Power Spectrogramìœ¼ë¡œ ìƒì„±í•œ í¬ë¡œë§ˆê·¸ë¨(Chromagram) ì…ë‹ˆë‹¤.

#### (3) Mel spectrum

â†ª ì˜¤ë””ì˜¤ ì‹ í˜¸(Time Domain)ì— Fast Fourier Transform(FFT)ë¥¼ ì ìš©í•˜ì—¬ ì–»ì€ ì£¼íŒŒìˆ˜ ì˜ì—­(Frequency Domain)ì˜ ìŠ¤í™íŠ¸ëŸ¼(Spectrum) ì…ë‹ˆë‹¤.

â†ª Mel Filter Bankë¥¼ ì‚¬ìš©í•œ í•„í„°ë§ ê³¼ì •ì„ ê±°ì³ Mel ìŠ¤í™íŠ¸ëŸ¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

#### (4) MFCC <sup>Mel-Frequency Cepstral Coefficient</sup>

â†ª Mel ìŠ¤í™íŠ¸ëŸ¼ì—ì„œ Cepstral ë¶„ì„ì„ í†µí•´ ê³ ìœ í•œ ìŒí–¥ íŠ¹ì„±ì„ ì¶”ì¶œí•œ ì§€í‘œì…ë‹ˆë‹¤.

#### (5) RMS <sup>Root Mean Square</sup>

â†ª ì˜¤ë””ì˜¤ í‰ê·  ìŒëŸ‰ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê°’ì…ë‹ˆë‹¤.

```python
def extract_features(sample):
    # ZCR
    result = np.array([])
    zcr = np.mean(librosa.feature.zero_crossing_rate(y = sample).T, axis=0)
    result=np.hstack((result, zcr)) 

    # Chroma_stft
    stft = np.abs(librosa.stft(sample))
    chroma_stft = np.mean(librosa.feature.chroma_stft(S = stft, sr = sample_rate).T, axis=0)
    result = np.hstack((result, chroma_stft))

    # MelSpectogram
    mel = np.mean(librosa.feature.melspectrogram(y = sample, sr = sample_rate).T, axis=0)
    result = np.hstack((result, mel)) 

    # MFCC
    mfcc = np.mean(librosa.feature.mfcc(y = sample, sr = sample_rate).T, axis=0)
    result = np.hstack((result, mfcc)) 

    # Root Mean Square Value
    rms = np.mean(librosa.feature.rms(y = sample).T, axis=0)
    result = np.hstack((result, rms)) 

    return result
```

&nbsp;
&nbsp;
&nbsp;

- Noise ì¶”ê°€, Time Stretching, Pitching ë°©ë²•ë“¤ì„ í†µí•´ í•œ ìŒì„±ë°ì´í„° ìƒ˜í”Œ ë‹¹ (1, 162) í¬ê¸°ì˜ Featureë¥¼ (3, 162) ë¡œ ì¦ê°•(Augmentation) í•©ë‹ˆë‹¤.

```python
def get_features(path):

    sample, sample_rate = librosa.load(path)
    
    # without augmentation
    res1 = extract_features(sample)
    result = np.array(res1)
    
    # sample with noise
    noise_sample = noise(sample)
    res2 = extract_features(noise_sample)
    result = np.vstack((result, res2)) 
    
    # sample with stretching and pitching
    str_sample = stretch(sample)
    sample_stretch_pitch = pitch(str_sample, sample_rate)
    res3 = extract_features(sample_stretch_pitch)
    result = np.vstack((result, res3)) 
    
    return result
```

&nbsp;
&nbsp;
&nbsp;

```python
labels = train['label']
x, y = [], []
for f, label in zip(file_name, labels):
    feature = get_features(train_path + f)
    for fe in feature:
        x.append(fe)
        y.append(label)

X = np.array(x)
Y = np.array(y)

print("Shape of X:", np.shape(X))
print("Shape of Y:", np.shape(Y))
```

<pre>
    Shape of X: (1200, 162)
    Shape of Y: (1200,)
</pre>


&nbsp;
&nbsp;
&nbsp;


----------------
## Reference

1. [Speech Emotion Recognition by SHIVAM BURNWAL](https://www.kaggle.com/code/shivamburnwal/speech-emotion-recognition)

