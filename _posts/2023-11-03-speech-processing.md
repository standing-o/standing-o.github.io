---
title: "íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ìŒì„± ë°ì´í„° ì „ì²˜ë¦¬ í•˜ê¸°"
date: 2023-11-03 17:00:00 +/-TTTT
categories: [ì¸ê³µì§€ëŠ¥ | AI, ì˜¤ë””ì˜¤ | Audio]
tags: [python, machine-learning, deep-learning, feature-engineering, audio-signal-processing, mfcc, melspectrogram, speech]
math: true
toc: true
author: seoyoung
img_path: /assets/img/for_post/
description: ğŸ™ï¸ ìŒì„± ë°ì´í„°ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ ì „ì²˜ë¦¬ì™€ íŠ¹ì„± ì¶”ì¶œ, ë°ì´í„° ì¦ê°• ê¸°ìˆ ë“¤ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.
---


------------------------

> **<u>KEYWORDS</u>**        
> ìŒì„± ì‹ í˜¸ ì²˜ë¦¬, ìŒì„± ì‹ í˜¸ ë””ì§€í„¸ ë³€í™˜, ìŒì„±ì‹ í˜¸ ì£¼íŒŒìˆ˜, MFCC ì¶”ì¶œ, MFCC íŠ¹ì§• ì¶”ì¶œ, MFCC Librosa, MFCC Mel Spectrogram, MFCC DCT, Trimming, Padding
{: .prompt-info }

-----------------------

&nbsp;
&nbsp;
&nbsp;

## **Introduction**
- ìŒì„± ë°ì´í„°ì— ëŒ€í•œ Feature Extractionì€ ìŒì„± ê´€ë ¨ ëª¨ë¸ë§ì—ì„œ ì¤‘ìš”í•œ ê³¼ì • ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. 
- Feature Extraction ì—ëŠ” ì—¬ëŸ¬ ê¸°ë²•ì´ ì‚¬ìš©ë˜ë©°, ìŒì„± ì‹ í˜¸ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ í‘œí˜„í•˜ê³  ë…¸ì´ì¦ˆë¥¼ ê°ì†Œì‹œì¼œ ë¨¸ì‹ ëŸ¬ë‹/ë”¥ëŸ¬ë‹ ëª¨ë¸ë§ì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜ì‹œì¼œ ì¤ë‹ˆë‹¤.
- íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ê°„ë‹¨í•˜ê²Œ ìŒì„±ì˜ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²• ë° ì—¬ëŸ¬ ì „ì²˜ë¦¬ ë°©ì‹ë“¤ì„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

&nbsp;
&nbsp;
&nbsp;

## **0. ìŒì„± ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**

```python
# Library 1. Librosa
import librosa
sr = 22050
data, sample_rate = librosa.load(path, sr=sr)

# Library 2. Scipy-Wavfile
from scipy.io import wavfile
sample_rate, data = wavfile.read(path)

# Library 3. Tensorflow
data, sample_rate = tf.audio.decode_wav(tf.io.read_file(path))

# Library 4. Torchaudio
import torchaudio
data, sample_rate = torchaudio.load(path)
```

- `data` ã…£ ì˜¤ë””ì˜¤ íŒŒì¼ì˜ íŒŒí˜• ë°ì´í„°ë¥¼ ë°°ì—´ë¡œ ë°˜í™˜í•œ ê²ƒì…ë‹ˆë‹¤.
- `sample_rate` ã…£ ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ ìƒ˜í”Œë§ ì†ë„, ì´ˆë‹¹ ìƒ˜í”Œë§ëœ ìŒì„± ë°ì´í„° í¬ì¸íŠ¸ì˜ ìˆ˜, Hzë‹¨ìœ„

&nbsp;
&nbsp;
&nbsp;

## **1. Audio Preprocessing**
### **Trimming**
- 60dB ì´í•˜ë¥¼ ë¬´ìŒìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
  - `top_db` ã…£ ìŒì„± ì‹ í˜¸ì˜ ìµœëŒ€ ì†ŒìŒ ë ˆë²¨ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ë¡œ ì´ ê°’ë³´ë‹¤ ì‘ì€ ë ˆë²¨ì˜ ì†ŒìŒì€ ì‚­ì œë©ë‹ˆë‹¤.
  - `frame_length` ã…£ í”„ë ˆì„ ê¸¸ì´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ë¡œ, ìŒì„± ë°ì´í„°ë¥¼ í”„ë ˆì„ìœ¼ë¡œ ë‚˜ëˆŒ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
  - `frame_stride` ã…£ í”„ë ˆì„ ê°„ê²©ì„ ë‚˜íƒ€ë‚´ëŠ” ë³€ìˆ˜ë¡œ, ì—°ì†ì ì¸ í”„ë ˆì„ ì‚¬ì´ì˜ ê°„ê²©ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.

```python
def trimming(data, sampling_rate, top_db = 60):
    
    frame_length = 0.025   # 0.025 ~ 0.05
    frame_stride = 0.010   # frame_length/2

    input_nfft = int(round(sampling_rate*frame_length))
    input_stride = int(round(sampling_rate*frame_stride))
    
    if len(np.shape(data)) == 1:
        trim_data = librosa.effects.trim(data, top_db=top_db, frame_length=input_nfft, hop_length=input_stride)[0]
    else:    
        trim_data = data.apply(lambda x : librosa.effects.trim(x, top_db=top_db, frame_length=input_nfft, hop_length=input_stride)[0])
      
    return trim_data
```

![fig1](20231103-1.png)

&nbsp;
&nbsp;
&nbsp;

### **Random Padding**
- ìŒì„± ë°ì´í„°ë“¤ì˜ ê¸¸ì´ê°€ ì„œë¡œ ë‹¤ë¥¸ ê²½ìš° Melspectrogram, MFCC ëª¨ë‘ ê¸¸ì´ê°€ ë‹¤ë¥´ë¯€ë¡œ, ê³ ì • ì‚¬ì´ì¦ˆë¥¼ ì •í•˜ê³  ëœë¤ìœ¼ë¡œ ì•ê³¼ ë’¤ì— Paddingì„ í•´ì¤ë‹ˆë‹¤.
- `reqlen` ã…£ í•„ìš”í•œ ìµœì¢… ë°ì´í„° ê¸¸ì´
  - ì…ë ¥ ë°ì´í„°ì˜ ê¸¸ì´ê°€ `reqlen`ë³´ë‹¤ ê¸¸ ê²½ìš°, `reqlen`ì— ë§ê²Œ ë°ì´í„°ë¥¼ ì˜ë¼ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.
  - ì…ë ¥ ë°ì´í„°ì˜ ê¸¸ì´ê°€ `reqlen`ê³¼ ê°™ì„ ê²½ìš°, ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
  - ì…ë ¥ ë°ì´í„°ì˜ ê¸¸ì´ê°€ `reqlen`ë³´ë‹¤ ì§§ì„ ê²½ìš°, ë¶€ì¡±í•œ ë¶€ë¶„ì„ ëœë¤í•œ ê°’ìœ¼ë¡œ ì±„ì›Œì„œ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ `reqlen`ì— ë§ê²Œ í™•ì¥í•©ë‹ˆë‹¤.

```python
def padding(x, reqlen=100000):
    x_len = x.shape[0]
    if reqlen < x_len:
        max_offset = x_len - reqlen
        offset = np.random.randint(max_offset)
        x = x[offset:(reqlen+offset)]
        return x
    elif reqlen == x_len:
        return x
    else:
        total_diff = reqlen - x_len
        offset = np.random.randint(total_diff)
        left_pad = offset
        right_pad = total_diff - offset
        return np.pad(x, (left_pad, right_pad), 'wrap')
```

![fig2](20231103-2.png)

&nbsp;
&nbsp;
&nbsp;

## **2. Audio Feature Extraction**
### **Spectrogram**
- Shape ã…£ [ì£¼íŒŒìˆ˜ ë°©í–¥ ì„±ë¶„ ìˆ˜ (n_fft / 2 + 1, `0Hz` ë¶€í„° `sample_rate`ì˜ ì ˆë°˜), Time ë°©í–¥ ì„±ë¶„ ìˆ˜]
  - `sample_rate`ì˜ ì ˆë°˜ì¸ ì´ìœ  ã…£ Nyquist Frequency
- `torchaudio`, `nn.Sequential`
  - `AmplitudeToDB` ã…£ Power ë‹¨ìœ„ì˜ Spectrogram ë˜ëŠ” Melspectrogramì„ dB(ë¡œê·¸) ë‹¨ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - dB ë‹¨ìœ„ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì´ ì´í•´í•˜ê¸° í¸í•œ ë²”ìœ„ì˜ ê°’ì„ ì œê³µí•©ë‹ˆë‹¤.
  - `n_fft` ã…£ `win_length`ì˜ í¬ê¸°ë¡œ ì˜ë¦° ìŒì„±ì˜ ì‘ì€ ì¡°ê°ì€ 0ìœ¼ë¡œ Padding ë˜ì–´ì„œ `n_fft`ë¡œ í¬ê¸°ê°€ ë§ì¶°ì§‘ë‹ˆë‹¤.  
    - ë”°ë¼ì„œ, `n_fft`ëŠ” `win_length` ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì•„ì•¼ í•˜ê³  ì¼ë°˜ì ìœ¼ë¡œ ì†ë„ë¥¼ ìœ„í•´ì„œ `2^n`ì˜ ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    - Paddingëœ ì¡°ê°ì— Fourier Transformì´ ì ìš©ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
  - `win_length` ã…£ ìŒì„±ì„ ì˜ë¼ì„œ ìƒê¸°ëŠ” ì‘ì€ ì¡°ê°ì˜ í¬ê¸°ì…ë‹ˆë‹¤.
    - 16000Hzì¸ ìŒì„±ì—ì„œëŠ” `400`ì— í•´ë‹¹í•˜ëŠ” ê°’ì…ë‹ˆë‹¤.
  - `hop_length` ã…£ ìŒì„±ì„ ì‘ì€ ì¡°ê°ìœ¼ë¡œ ìë¥¼ ë•Œ ìë¥´ëŠ” ê°„ê²©ì— í•´ë‹¹í•©ë‹ˆë‹¤.
    - 16000Hzì¸ ìŒì„±ì—ì„œëŠ” 160ì— í•´ë‹¹í•˜ëŠ” ê°’

```python
spectrogram = nn.Sequential(
    AT.Spectrogram(n_fft=512, 
                   win_length=400, 
                   hop_length=160),
    AT.AmplitudeToDB()
)

spec = spectrogram(sample_data)
```

&nbsp;
&nbsp;
&nbsp;

### **Melspectrogram**
- ìŒì„±ë°ì´í„°ë¥¼ Frequency, Timeì˜ 2ì°¨ì› ë„ë©”ì¸ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- Shape ã…£ [ì£¼íŒŒìˆ˜ ë°©í–¥ ì„±ë¶„ ìˆ˜, Time ë°©í–¥ ì„±ë¶„ ìˆ˜]
- `librosa.feature.melspectrogram`
  - `n_mels` ã…£ Melspectrogramì˜ ì£¼íŒŒìˆ˜ í•´ìƒë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
  - `power_to_db` ã…£ Melspectrogramì„ ë°ì‹œë²¨ë¡œ ìŠ¤ì¼€ì¼ë§í•˜ì—¬ íŠ¹ì§•ì„ ê°•ì¡°í•©ë‹ˆë‹¤.
  - `ref=np.max` ã…£ ë°ì‹œë²¨ë¡œ ë³€í™˜ ì‹œ ì‚¬ìš©ë˜ëŠ” ì°¸ì¡° ê°’ì…ë‹ˆë‹¤.

```python
# Library 1: Librosa
S = librosa.feature.melspectrogram(data, sr=sample_rate, n_mels=40)
log_S = librosa.power_to_db(S, ref=np.max)
librosa.display.specshow(log_S, sr=sr)  # x axis: Time, y axis: Frequency
```

&nbsp;
&nbsp;
&nbsp;

- `torchaudio`, `nn.Sequential`
  - `n_mels` ã…£ ì ìš©í•  Mel Filterì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

```python
# Library 2: Torchaudio
mel_spectrogram = nn.Sequential(
    AT.MelSpectrogram(sample_rate=22, 
                      n_fft=512, 
                      win_length=400,
                      hop_length=160,
                      n_mels=80),
    AT.AmplitudeToDB()
)
mel = mel_spectrogram(sample_data)
```

![fig3](20231103-3.png)

- `win_length`ê°€ ì»¤ì§ˆìˆ˜ë¡ ì£¼íŒŒìˆ˜ ì„±ë¶„ì— ëŒ€í•œ í•´ìƒë„ëŠ” ë†’ì•„ì§€ì§€ë§Œ, ì‹œê°„ ì„±ë¶„ì— ëŒ€í•œ í•´ìƒë„ëŠ” ë‚®ì•„ì§‘ë‹ˆë‹¤.
- `win_length`ê°€ ì‘ì€ ê²½ìš°ì—ëŠ” ì£¼íŒŒìˆ˜ ì„±ë¶„ì— ëŒ€í•œ í•´ìƒë„ëŠ” ë‚®ì•„ì§€ì§€ë§Œ, ì‹œê°„ ì„±ë¶„ì— ëŒ€í•œ í•´ìƒë„ëŠ” ë†’ì•„ì§€ê²Œ ë©ë‹ˆë‹¤.
- `n_fft`ë¥¼ ë†’ì´ë©´ ì£¼íŒŒìˆ˜ ì„±ë¶„ì˜ ìˆ˜ëŠ” ì¦ê°€í•˜ì§€ë§Œ ì‹¤ì œ ì£¼íŒŒìˆ˜ì˜ í•´ìƒë„ëŠ” ì¦ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

&nbsp;
&nbsp;
&nbsp;

### **MFCC**

```python
mfcc = librosa.feature.mfcc(data, sr=sample_rate, n_mels=40)
librosa.display.specshow(mfcc, sr=sample_rate)  # x axis: Time, y axis: MFCC coefficients
```

&nbsp;
&nbsp;
&nbsp;

### **Stacked Melspectrogram**
- Melspectrogramì˜ 1ì°¨ ë¯¸ë¶„ê³¼ 2ì°¨ ë¯¸ë¶„ì„ ì±„ë„ë¡œ Stacking í•˜ì—¬ ìŒì„±ì— ëŒ€í•œ ë³€í™”ìœ¨ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
def stacked_melspectrogram(data):

    frame_length = 0.025
    frame_stride = 0.010

    input_nfft = int(round(sampling_rate*frame_length))
    input_stride = int(round(sampling_rate*frame_stride))

    extracted_features = []
    for i in data:
        
        if feature == "mfcc":
            n_feature = 40
            S = librosa.feature.mfcc(y=i,
                                     sr=sampling_rate,
                                     n_mfcc=n_feature,
                                     n_fft=input_nfft,
                                     hop_length=input_stride)
            S_delta = librosa.feature.delta(S)
            S_delta2 = librosa.feature.delta(S, order=2)
            
        elif feature == "melspec":
            n_feature = 128
            S = librosa.feature.melspectrogram(y=i,
                                               sr=sampling_rate,
                                               n_mels=n_feature,
                                               n_fft=input_nfft,
                                               hop_length=input_stride)
            S = librosa.power_to_db(S, ref=np.max)
            S_delta = librosa.feature.delta(S)
            S_delta2 = librosa.feature.delta(S, order=2)
            
        S = np.stack((S, S_delta, S_delta2), axis=2)
        extracted_features.append(S)
        
    return np.array(extracted_features)
```

&nbsp;
&nbsp;
&nbsp;

### **Multi-Resolution Melspectrogram**
- 4ê°€ì§€ì˜ ì„œë¡œ ë‹¤ë¥¸ `win_length`ë¡œ ë‹¤ì–‘í•œ í•´ìƒë„ë¥¼ ê°€ì§„ Melspectrogramë“¤ì„ Stackingí•˜ê³  Normalizing í•©ë‹ˆë‹¤.

```python
def melspectrogram(win_length):
        mels = nn.Sequential(
            AT.MelSpectrogram(sample_rate=16000, n_fft=2048, win_length=win_length,
                              hop_length=100, pad=50,f_min=25,f_max=7500,n_mels=160),
            AT.AmplitudeToDB())
        return mels

mels_1 = melspectrogram(250)[0, :, 1:-1]
mels_2 = melspectrogram(500)[0, :, 1:-1]
mels_3 = melspectrogram(750)[0, :, 1:-1]
mels_4 = melspectrogram(1000)[0, :, 1:-1]

device = 'cuda' if torch.cuda.is_available() else 'cpu'
cali = torch.linspace(-0.5, 0.5, steps=160, device=device).view(1, -1, 1)

stacked_mels = torch.stack([mels_1, mels_2, mels_3, mels_4], dim=0)
stacked_mels = (stacked_mels - stacked_mels.mean(dim=[1, 2], keepdim=True)) / 20 + cali
```

![fig4](20231103-4.png)

&nbsp;
&nbsp;
&nbsp;

## **3. Data Augmentation**

### **Noising**
- ëœë¤ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.

```python
def noising(data,noise_factor):
    noise = np.random.randn(len(data))
    augmented_data = data + noise_factor * noise
    augmented_data = augmented_data.astype(type(data[0]))
    return augmented_data
```

&nbsp;
&nbsp;
&nbsp;

### **Shifting**
- ì¢Œìš°ë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.

```python
def shifting(data, sampling_rate, shift_max, shift_direction):
    shift = np.random.randint(sampling_rate * shift_max+1)
    if shift_direction == 'right':
        shift = -shift
    elif shift_direction == 'both':
        direction = np.random.randint(0, 2)
        if direction == 1:
            shift = -shift
    augmented_data = np.roll(data, shift)
    # Set to silence for heading/ tailing
    if shift > 0:
        augmented_data[:shift] = 0
    else:
        augmented_data[shift:] = 0
    return augmented_data
```

&nbsp;
&nbsp;
&nbsp;

### **Pitch**
- í”¼ì¹˜ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.

```python
def change_pitch(data, sampling_rate, pitch_factor):
    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)
```

&nbsp;
&nbsp;
&nbsp;

### **SpecAugment**
- `feat_size` ë° `seq_len`ì„ ê³„ì‚°í•˜ì—¬ Spectrogramì˜ í¬ê¸°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
- `freq_mask`ë¥¼ ì ìš©í•˜ì—¬ ì£¼ì–´ì§„ `freq_mask_num`ë§Œí¼ ì£¼íŒŒìˆ˜ ì¶•ì—ì„œ ì¼ë¶€ ì£¼íŒŒìˆ˜ë¥¼ ë¬´ì‘ìœ„ë¡œ ì œê±°í•˜ì—¬ ë°ì´í„°ë¥¼ ë³€í˜•í•©ë‹ˆë‹¤.
- `time_mask`ë¥¼ ì ìš©í•˜ì—¬ ì£¼ì–´ì§„ `time_mask_num`ë§Œí¼ ì‹œê°„ ì¶•ì—ì„œ ì¼ë¶€ ì‹œê°„ì ì¸ ì •ë³´ë¥¼ ë¬´ì‘ìœ„ë¡œ ì œê±°í•˜ì—¬ ë°ì´í„°ë¥¼ ë³€í˜•í•©ë‹ˆë‹¤.

```python
time_mask = 32
freq_mask = 32
n_time_mask = 1
n_freq_mask = 1

def SpecAugment(spec, T=time_mask, F=freq_mask, time_mask_num=n_time_mask, freq_mask_num=n_freq_mask):
    feat_size = spec.shape[0]
    seq_len = spec.shape[1]
    
    # freq mask
    for _ in range(freq_mask_num):
        f = np.random.uniform(low=0.0, high=F)
        f = int(f)
        f0 = random.randint(0, feat_size - f)
        spec[:, f0 : f0 + f] = 0
    # time mask
    for _ in range(time_mask_num):
        t = np.random.uniform(low=0.0, high=T)
        t = int(t)
        t0 = random.randint(0, seq_len - t)
        spec[t0 : t0 + t] = 0
    return spec
```

&nbsp;
&nbsp;
&nbsp;

ì´ëŸ¬í•œ ê¸°ë²•ë“¤ì„ ë¹„êµí•˜ë©´ì„œ ëª¨ë¸ì— ë§ëŠ” íŠ¹ì„±ì„ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•œë‹¤ë©´ AI ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
